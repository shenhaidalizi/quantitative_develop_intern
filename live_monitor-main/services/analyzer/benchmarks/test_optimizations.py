"""
ç»¼åˆæµ‹è¯•è„šæœ¬ï¼šéªŒè¯æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½
"""

import time
import os
import sys
import numpy as np
import pandas as pd
from datetime import datetime, timedelta

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from preprocess_data import (
    save_data_as_parquet, 
    load_data_from_parquet,
    OUTPUT_DIR
)
from timely_data import get_z_score, CONFIG


class TestResults:
    """æµ‹è¯•ç»“æœæ”¶é›†å™¨"""
    def __init__(self):
        self.results = {}
        self.start_time = time.time()
    
    def add_result(self, test_name, passed, message="", duration=None):
        self.results[test_name] = {
            'passed': passed,
            'message': message,
            'duration': duration
        }
    
    def print_summary(self):
        print("\n" + "="*70)
        print("æµ‹è¯•æ€»ç»“")
        print("="*70)
        
        passed_count = sum(1 for r in self.results.values() if r['passed'])
        total_count = len(self.results)
        
        for test_name, result in self.results.items():
            status = "âœ… PASS" if result['passed'] else "âŒ FAIL"
            duration_str = f" ({result['duration']:.2f}ç§’)" if result['duration'] else ""
            print(f"{status} | {test_name}{duration_str}")
            if result['message']:
                print(f"       {result['message']}")
        
        print("="*70)
        print(f"æ€»è®¡: {passed_count}/{total_count} æµ‹è¯•é€šè¿‡")
        print(f"æ€»è€—æ—¶: {time.time() - self.start_time:.2f}ç§’")
        print("="*70)


def generate_time_str(index):
    """ç”Ÿæˆåˆæ³•çš„äº¤æ˜“æ—¶é—´å­—ç¬¦ä¸²"""
    base_time = datetime.strptime("09:31:00", "%H:%M:%S")
    new_time = base_time + timedelta(minutes=index)
    return new_time.strftime("%H:%M:%S")


def generate_test_data(num_times=10, num_stocks=100):
    """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
    print(f"ğŸ“Š ç”Ÿæˆæµ‹è¯•æ•°æ®: {num_times}ä¸ªæ—¶é—´ç‚¹ Ã— {num_stocks}åªè‚¡ç¥¨...")
    
    final_data = {}
    for i in range(num_times):
        time_str = generate_time_str(i)
        final_data[time_str] = {}
        
        for j in range(num_stocks):
            stock_code = f"60{j:04d}"
            final_data[time_str][stock_code] = {
                'rolling1': {
                    'mean': round(np.random.uniform(100, 10000), 2),
                    'std': round(np.random.uniform(10, 500), 2)
                },
                'rolling5': {
                    'mean': round(np.random.uniform(500, 50000), 2),
                    'std': round(np.random.uniform(50, 2500), 2)
                },
                'rolling10': {
                    'mean': round(np.random.uniform(1000, 100000), 2),
                    'std': round(np.random.uniform(100, 5000), 2)
                },
                'rolling30': {
                    'mean': round(np.random.uniform(3000, 300000), 2),
                    'std': round(np.random.uniform(300, 15000), 2)
                },
                'rolling_full': {
                    'mean': round(np.random.uniform(5000, 500000), 2),
                    'std': round(np.random.uniform(500, 25000), 2)
                }
            }
    
    return final_data


def test_parquet_performance(test_data, results):
    """æµ‹è¯•1: Parquetè¯»å†™æ€§èƒ½"""
    print("\nğŸ“ˆ æµ‹è¯•1: Parquetè¯»å†™æ€§èƒ½...")
    
    test_file = os.path.join(OUTPUT_DIR, "test_performance.parquet")
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # å†™å…¥æµ‹è¯•
    start_time = time.time()
    save_data_as_parquet(test_data, test_file.replace('.parquet', '.json'))
    write_time = time.time() - start_time
    
    file_size = os.path.getsize(test_file) / (1024 * 1024)
    print(f"  âœ“ å†™å…¥è€—æ—¶: {write_time:.3f}ç§’")
    print(f"  âœ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
    
    # è¯»å–æµ‹è¯•
    start_time = time.time()
    loaded_data = load_data_from_parquet(test_file)
    read_time = time.time() - start_time
    
    print(f"  âœ“ è¯»å–è€—æ—¶: {read_time:.3f}ç§’")
    
    # æ¸…ç†
    if os.path.exists(test_file):
        os.remove(test_file)
    
    # æ€§èƒ½åˆ¤æ–­
    passed = write_time < 5 and read_time < 3
    message = f"å†™å…¥: {write_time:.3f}ç§’, è¯»å–: {read_time:.3f}ç§’, æ–‡ä»¶: {file_size:.2f}MB"
    results.add_result("Parquetè¯»å†™æ€§èƒ½", passed, message, write_time + read_time)


def test_data_integrity(test_data, results):
    """æµ‹è¯•2: æ•°æ®å®Œæ•´æ€§"""
    print("\nğŸ” æµ‹è¯•2: æ•°æ®å®Œæ•´æ€§æ£€æŸ¥...")
    
    test_file = os.path.join(OUTPUT_DIR, "test_integrity.parquet")
    
    # ä¿å­˜å’Œè¯»å–
    save_data_as_parquet(test_data, test_file.replace('.parquet', '.json'))
    loaded_data = load_data_from_parquet(test_file)
    
    # æ£€æŸ¥æ—¶é—´ç‚¹æ•°é‡
    time_check = len(test_data) == len(loaded_data)
    print(f"  {'âœ“' if time_check else 'âœ—'} æ—¶é—´ç‚¹æ•°é‡: {len(test_data)} == {len(loaded_data)}")
    
    # æ£€æŸ¥è‚¡ç¥¨æ•°é‡
    stock_counts_match = True
    for time_str in test_data.keys():
        if len(test_data[time_str]) != len(loaded_data.get(time_str, {})):
            stock_counts_match = False
            break
    print(f"  {'âœ“' if stock_counts_match else 'âœ—'} è‚¡ç¥¨æ•°é‡åŒ¹é…")
    
    # æ£€æŸ¥æ•°å€¼ç²¾åº¦
    precision_check = True
    sample_time = list(test_data.keys())[0]
    sample_stock = list(test_data[sample_time].keys())[0]
    
    original = test_data[sample_time][sample_stock]['rolling5']['mean']
    loaded = loaded_data[sample_time][sample_stock]['rolling5']['mean']
    diff = abs(original - loaded)
    
    if diff > 0.01:
        precision_check = False
    print(f"  {'âœ“' if precision_check else 'âœ—'} æ•°å€¼ç²¾åº¦: è¯¯å·®={diff:.6f}")
    
    # æ¸…ç†
    if os.path.exists(test_file):
        os.remove(test_file)
    
    passed = time_check and stock_counts_match and precision_check
    message = f"æ—¶é—´ç‚¹: {time_check}, è‚¡ç¥¨æ•°: {stock_counts_match}, ç²¾åº¦: {precision_check}"
    results.add_result("æ•°æ®å®Œæ•´æ€§", passed, message)


def test_zero_handling(results):
    """æµ‹è¯•3: 0å€¼å¤„ç†ä¼˜åŒ–"""
    print("\nğŸ”¢ æµ‹è¯•3: 0å€¼å¤„ç†ä¼˜åŒ–...")
    
    test_df = pd.DataFrame({
        'rolling5': [100, 200, 100, 150],
        'rolling5_mean': [100, 200, 100, 150],
        'rolling5_std': [10, 0, 0, 20]
    })
    
    print("  æµ‹è¯•åœºæ™¯:")
    print("  - åœºæ™¯1: std=10, diff=0 â†’ æœŸæœ›z-score=0")
    print("  - åœºæ™¯2: std=0, diff=0 â†’ æœŸæœ›z-score=0")
    print("  - åœºæ™¯3: std=0, diff=0 â†’ æœŸæœ›z-score=0")
    print("  - åœºæ™¯4: std=20, diff=0 â†’ æœŸæœ›z-score=0")
    
    result_df = get_z_score(test_df, [5])
    z_scores = result_df['rolling5_z_score'].values
    
    finite_check = np.all(np.isfinite(z_scores))
    print(f"  {'âœ“' if finite_check else 'âœ—'} æ‰€æœ‰z-scoreä¸ºæœ‰é™å€¼: {z_scores}")
    
    zero_diff_zero_std = z_scores[1] == 0 and z_scores[2] == 0
    print(f"  {'âœ“' if zero_diff_zero_std else 'âœ—'} std=0ä¸”diff=0æ—¶z-score=0")
    
    normal_zero = z_scores[0] == 0 and z_scores[3] == 0
    print(f"  {'âœ“' if normal_zero else 'âœ—'} æ­£å¸¸æƒ…å†µä¸‹z-scoreæ­£ç¡®")
    
    passed = finite_check and zero_diff_zero_std and normal_zero
    message = f"æœ‰é™å€¼: {finite_check}, é›¶å¤„ç†: {zero_diff_zero_std}, æ­£å¸¸å€¼: {normal_zero}"
    results.add_result("0å€¼å¤„ç†ä¼˜åŒ–", passed, message)


def test_extreme_std_handling(results):
    """æµ‹è¯•4: æç«¯æ ‡å‡†å·®å¤„ç†"""
    print("\nâš¡ æµ‹è¯•4: æç«¯æ ‡å‡†å·®å¤„ç†...")
    
    test_df = pd.DataFrame({
        'rolling5': [1000, 2000, 3000, 100],
        'rolling5_mean': [100, 100, 100, 100],
        'rolling5_std': [0.000001, 0, 0.000001, 10]
    })
    
    result_df = get_z_score(test_df, [5])
    z_scores = result_df['rolling5_z_score'].values
    
    print(f"  æµ‹è¯•ç»“æœ:")
    print(f"  - æå°std (1e-6), å¤§diff (900): z={z_scores[0]:.2f}")
    print(f"  - é›¶std, å¤§diff (1900): z={z_scores[1]:.2f}")
    print(f"  - æå°std, å¤§diff (2900): z={z_scores[2]:.2f}")
    print(f"  - æ­£å¸¸std (10), å°diff (0): z={z_scores[3]:.2f}")
    
    extreme_handled = np.all(np.abs(z_scores[:3]) >= 3) and np.all(np.abs(z_scores[:3]) <= 5)
    normal_correct = z_scores[3] == 0
    
    passed = extreme_handled and normal_correct
    message = f"æç«¯å¤„ç†: {extreme_handled}, æ­£å¸¸å¤„ç†: {normal_correct}"
    results.add_result("æç«¯æ ‡å‡†å·®å¤„ç†", passed, message)


def test_file_size_reduction(test_data, results):
    """æµ‹è¯•5: æ–‡ä»¶å¤§å°ä¼˜åŒ–"""
    print("\nğŸ’¾ æµ‹è¯•5: æ–‡ä»¶å¤§å°ä¼˜åŒ–ï¼ˆ15å¤© vs 30å¤©ï¼‰...")
    
    large_data_15 = {}
    large_data_30 = {}
    
    for i in range(240):
        time_str = generate_time_str(i)
        large_data_15[time_str] = test_data[list(test_data.keys())[0]].copy()
    
    for i in range(480):
        time_str = generate_time_str(i)
        large_data_30[time_str] = test_data[list(test_data.keys())[0]].copy()
    
    file_15 = os.path.join(OUTPUT_DIR, "test_15days.parquet")
    file_30 = os.path.join(OUTPUT_DIR, "test_30days.parquet")
    
    save_data_as_parquet(large_data_15, file_15.replace('.parquet', '.json'))
    size_15 = os.path.getsize(file_15) / (1024 * 1024)
    
    save_data_as_parquet(large_data_30, file_30.replace('.parquet', '.json'))
    size_30 = os.path.getsize(file_30) / (1024 * 1024)
    
    reduction_percent = (1 - size_15 / size_30) * 100
    
    print(f"  âœ“ 15å¤©æ•°æ®æ–‡ä»¶: {size_15:.2f} MB")
    print(f"  âœ“ 30å¤©æ•°æ®æ–‡ä»¶: {size_30:.2f} MB")
    print(f"  âœ“ å‡å°‘æ¯”ä¾‹: {reduction_percent:.1f}%")
    
    for f in [file_15, file_30]:
        if os.path.exists(f):
            os.remove(f)
    
    passed = reduction_percent > 40
    message = f"15å¤©: {size_15:.2f}MB, 30å¤©: {size_30:.2f}MB, å‡å°‘: {reduction_percent:.1f}%"
    results.add_result("æ–‡ä»¶å¤§å°ä¼˜åŒ–", passed, message)


def test_nan_handling(results):
    """æµ‹è¯•6: NaNå¤„ç†"""
    print("\nğŸ” æµ‹è¯•6: NaNå¤„ç†ï¼ˆç¼ºå¤±æ•°æ®æ—¶ä¸å†è®¾ä¸º0ï¼‰...")
    
    test_df = pd.DataFrame({
        'rolling5': [100, 200, 300],
        'rolling5_mean': [90, 180, np.nan],
        'rolling5_std': [10, 20, 30]
    })
    
    try:
        result_df = get_z_score(test_df, [5])
        z_scores = result_df['rolling5_z_score'].values
        
        first_two_finite = np.isfinite(z_scores[0]) and np.isfinite(z_scores[1])
        third_is_nan = np.isnan(z_scores[2])
        
        print(f"  âœ“ æ­£å¸¸æ•°æ®z-score: [{z_scores[0]:.2f}, {z_scores[1]:.2f}]")
        print(f"  âœ“ ç¼ºå¤±æ•°æ®z-score: {z_scores[2]} (åº”ä¸ºnan)")
        
        passed = first_two_finite and third_is_nan
        message = f"æ­£å¸¸æ•°æ®æœ‰é™: {first_two_finite}, ç¼ºå¤±æ•°æ®ä¸ºNaN: {third_is_nan}"
    except Exception as e:
        passed = False
        message = f"å¤„ç†å¼‚å¸¸: {str(e)}"
    
    results.add_result("NaNå¤„ç†", passed, message)


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("è‚¡ç¥¨åˆ†æä¼˜åŒ–åŠŸèƒ½ç»¼åˆæµ‹è¯•")
    print("="*70)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print("="*70)
    
    results = TestResults()
    
    test_data = generate_test_data(num_times=10, num_stocks=50)
    
    test_parquet_performance(test_data, results)
    test_data_integrity(test_data, results)
    test_zero_handling(results)
    test_extreme_std_handling(results)
    test_file_size_reduction(test_data, results)
    test_nan_handling(results)
    
    results.print_summary()
    
    return all(r['passed'] for r in results.results.values())


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
